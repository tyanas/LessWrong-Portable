<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en-US">
<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<link rel="canonical" href="https://www.readthesequences.com/The-Design-Space-Of-Minds-In-General" />
	<title>The Design Space of Minds-in-General  </title>
	<meta name="viewport" content="width=device-width, initial-scale=1"/>
	<link rel='stylesheet' href='https://www.readthesequences.com/wiki/pub/skins/readthesequences/skin.css' type='text/css' />
	<!--HTMLHeader--><style type='text/css'><!--.TCprogress {background-color:#5af; min-height:13px; width:13px; color:#fff; margin-left:auto; margin-right:auto;}
table.TotalCounter td {font-size:x-small; text-align:center}a[href^='http://archive.is/timegate/'] { opacity: 0.5;  }

.footnote_block_begin {
	width: 160px;
	border-bottom: 1px solid blue;
	margin-bottom: 0.5em;
}
div.footnote {
	margin: 0 3em 0.5em 0;
	padding-left: 2em;
	font-size: 0.9em;
	position: relative;
}
div.footnote .footnote-number {
	position: absolute;
	left: 0;
	width: 1.5em;
	text-align: right;
}
div.footnote .footnote-number::after {
	content: '.';
}
.num { position: relative; font-size: 0.7em; bottom: 0.5em; right: 0.1em; margin-left: 0.15em; }
.frasl { font-size: 1.15em; line-height: 1; }
.denom { position: relative; font-size: 0.7em; top: 0.05em; left: 0.1em; }

#wikitext .article-talk-selector a:nth-of-type(3) { color: #8e7500; }

--></style><meta http-equiv='Content-Type' content='text/html; charset=utf-8' /><link href="/wiki/uploads/favicon.png" type="image/png" rel="shortcut icon" /><link rel='preload' href='https://www.readthesequences.com/wiki/fonts/font_files/GaramondPremierProSubhead/GaramondPremierProSubhead-Medium.otf' type='font/otf' as='font' crossorigin />
<link rel='preload' href='https://www.readthesequences.com/wiki/fonts/font_files/ProximaNova/ProximaNova-Thin.otf' type='font/otf' as='font' crossorigin />
  <meta name='robots' content='index,follow' />

</head>
<body>
<!--PageText-->
<div id='wikitext'>
<div class='article-talk-selector' >
<p><a target='blank'  class='wikilink' href='https://www.readthesequences.com/The-Design-Space-Of-Minds-In-General?action=source' title='View PmWiki source for “The Design Space of Minds-in-General”'>Source</a><a target='blank'  class='wikilink' href='https://www.readthesequences.com/The-Design-Space-Of-Minds-In-General?action=markdown' title='View “The Design Space of Minds-in-General” in Markdown format'>Markdown</a> · <a rel='nofollow'  class='wikilink' href='https://www.readthesequences.com/Talk/The-Design-Space-Of-Minds-In-General' title='View the Talk page for “The Design Space of Minds-in-General”'>Talk</a>
</p></div>
<div class='nav_menu' >
<p><a class='wikilink' href='https://www.readthesequences.com/'>Home</a><a class='wikilink' href='https://www.readthesequences.com/About'>About</a><a class='urllink' href='https://www.readthesequences.com/Search' rel='nofollow'>Search</a><a class='wikilink' href='https://www.readthesequences.com/Contents'>Contents</a>
</p></div>
<h1>The Design Space of Minds-in-General</h1>
<p  style='text-align: center;'> ❦
</p>
<p>People ask me, “What will Artificial Intelligences be like? What will they do? Tell us your amazing story about the future.”
</p>
<p>And lo, I say unto them, “You have asked me a trick question.”
</p>
<p>ATP synthase is a molecular machine—one of three known occasions when evolution has invented the freely rotating wheel—that is essentially the same in animal mitochondria, plant chloroplasts, and bacteria. ATP synthase has not changed significantly since the rise of eukaryotic life two billion years ago. It’s something we <em>all</em> have in common—thanks to the way that evolution <a class='urllink' href='https://www.greaterwrong.com/lw/rl/the_psychological_unity_of_humankind/' rel='nofollow'>strongly conserves certain genes</a>; once many other genes depend on a gene, a mutation will tend to break all the dependencies.
</p>
<p>Any two AI designs might be less similar to each other than you are to a petunia. Asking what “AIs” will do is a trick question because it implies that all AIs form a <a class='wikilink' href='https://www.readthesequences.com/SimilarityClusters'>natural class</a>. Humans do form a natural class because we all share the same brain architecture. But when you say “Artificial Intelligence,” you are referring to a vastly larger <em>space of possibilities</em> than when you say “human.” When people talk about “AIs” we are really talking about <em>minds-in-general</em>, or optimization processes in general. Having a word for “AI” is like having a word for everything that isn’t a duck.
</p>
<p>Imagine a map of mind design space… this is one of my standard diagrams…
</p>
<p  style='text-align: center;'> &nbsp; <img src='../images/TheDesignSpaceOfMindsInGeneral_diagram_1.svg' alt='diagram: the design space of minds in general' title='diagram: the design space of minds in general' /> &nbsp;
</p>
<p>All humans, of course, fit into a tiny little dot—as a sexually reproducing species, <a class='urllink' href='https://www.greaterwrong.com/lw/rl/the_psychological_unity_of_humankind/' rel='nofollow'>we can’t be too different from one another</a>.
</p>
<p>This tiny dot belongs to a wider ellipse, the space of transhuman mind designs—things that might be smarter than us, or much smarter than us, but that in some sense would still be people as we understand people.
</p>
<p>This transhuman ellipse is within a still wider volume, the space of posthuman minds, which is everything that a transhuman might grow up into.
</p>
<p>And then the rest of the sphere is the space of minds-in-general, including possible Artificial Intelligences so odd that they aren’t even <em>posthuman</em>.
</p>
<p>But wait—natural selection designs complex artifacts and selects among complex strategies. So where is natural selection on this map?
</p>
<p>So this entire map really floats in a still vaster space, the space of optimization processes. At the bottom of this vaster space, below even humans, is natural selection as it first began in some tidal pool: mutate, replicate, and sometimes die, no sex.
</p>
<p>Are there any powerful optimization processes, with strength comparable to a human civilization or even a self-improving AI, which we would not recognize as minds? Arguably <a class='urllink' href='http://www.hutter1.net/ai/' rel='nofollow'>Marcus Hutter’s</a> <a class='urllink' href='https://wiki.lesswrong.com/wiki/AIXI' rel='nofollow'>AIXI</a> should go in this category: for a mind of infinite power, it’s awfully stupid—poor thing can’t even recognize itself in a mirror. But that is a topic for another time.
</p>
<p>My primary moral is to <em>resist the temptation to generalize over all of mind design space</em>.
</p>
<p>If we focus on the bounded subspace of mind design space that contains all those minds whose makeup can be specified in a trillion bits or less, then every universal generalization that you make has two to the trillionth power chances to be falsified.
</p>
<p>Conversely, every <em>existential</em> generalization—“there exists at least one mind such that <em>X</em>”—has two to the trillionth power chances to be true.
</p>
<p>So you want to resist the temptation to say either that <em>all</em> minds do something, or that <em>no</em> minds do something.
</p>
<p>The main reason you could find yourself thinking that you know what a fully generic mind will (won’t) do is if you put yourself in that mind’s shoes— imagine what you would do in that mind’s place—and get back a generally wrong, anthropomorphic answer. (Albeit that it is true in at least one case, since you are yourself an example.) Or if you imagine a mind doing something, and then imagining the reasons <em>you</em> wouldn’t do it—so that you imagine that a mind of that type can’t exist, that the <a class='wikilink' href='https://www.readthesequences.com/GhostsInTheMachine'>ghost in the machine</a> will look over the corresponding source code and hand it back.
</p>
<p>Somewhere in mind design space is at least one mind with almost any kind of logically consistent property you care to imagine.
</p>
<p>And this is important because it emphasizes the importance of discussing <em>what happens, lawfully, and why</em>, as a causal result of a mind’s particular constituent makeup; somewhere in mind design space is a mind that does it differently.
</p>
<p>Of course, you could always say that anything that doesn’t do it your way is “<a class='wikilink' href='https://www.readthesequences.com/ArguingByDefinition'>by definition</a>” not a mind; after all, it’s obviously stupid. I’ve seen people try that one too.
</p>

<div class='bottom_nav bottom_nav_post' >
<p><a class='wikilink' href='https://www.readthesequences.com/DreamsOfAIDesign'>Dreams of AI Design</a>
</p>
<p><a class='wikilink' href='https://www.readthesequences.com/Contents'>Top</a>
</p>
<p><a class='wikilink' href='https://www.readthesequences.com/Book-V-MereGoodness'>Book</a>
</p>
<p><a class='wikilink' href='https://www.readthesequences.com/FakePreferencesSequence'>Sequence</a>
</p>
<p><a class='wikilink' href='https://www.readthesequences.com/ValueTheorySequence'>Value Theory<br clear='all' /><span style='font-size:83%'>(sequence)</span></a>
</p></div>
</div>

<!--PageActionFmt--><!--/PageActionFmt-->
<!--HTMLFooter-->
</body>
</html>

